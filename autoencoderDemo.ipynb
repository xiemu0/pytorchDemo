{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.05\n",
    "DOWNLOAD_MNIST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=True, \n",
    "    transform=torchvision.transforms.ToTensor(), # [0, 1]\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | step: 0 | loss: 0.23356093\n",
      "epoch: 0 | step: 100 | loss: 0.1000998\n",
      "epoch: 0 | step: 200 | loss: 0.09430057\n",
      "epoch: 0 | step: 300 | loss: 0.09548191\n",
      "epoch: 0 | step: 400 | loss: 0.09462469\n",
      "epoch: 0 | step: 500 | loss: 0.10681672\n",
      "epoch: 0 | step: 600 | loss: 0.10904447\n",
      "epoch: 0 | step: 700 | loss: 0.10872734\n",
      "epoch: 0 | step: 800 | loss: 0.1126591\n",
      "epoch: 0 | step: 900 | loss: 0.10833494\n",
      "epoch: 1 | step: 0 | loss: 0.11285478\n",
      "epoch: 1 | step: 100 | loss: 0.12388151\n",
      "epoch: 1 | step: 200 | loss: 0.1217552\n",
      "epoch: 1 | step: 300 | loss: 0.12662393\n",
      "epoch: 1 | step: 400 | loss: 0.11964496\n",
      "epoch: 1 | step: 500 | loss: 0.11983156\n",
      "epoch: 1 | step: 600 | loss: 0.123668395\n",
      "epoch: 1 | step: 700 | loss: 0.12597476\n",
      "epoch: 1 | step: 800 | loss: 0.13131483\n",
      "epoch: 1 | step: 900 | loss: 0.11978414\n",
      "epoch: 2 | step: 0 | loss: 0.12191874\n",
      "epoch: 2 | step: 100 | loss: 0.11584893\n",
      "epoch: 2 | step: 200 | loss: 0.118880704\n",
      "epoch: 2 | step: 300 | loss: 0.1269394\n",
      "epoch: 2 | step: 400 | loss: 0.12453502\n",
      "epoch: 2 | step: 500 | loss: 0.12548678\n",
      "epoch: 2 | step: 600 | loss: 0.1311191\n",
      "epoch: 2 | step: 700 | loss: 0.1291951\n",
      "epoch: 2 | step: 800 | loss: 0.12870722\n",
      "epoch: 2 | step: 900 | loss: 0.13078031\n",
      "epoch: 3 | step: 0 | loss: 0.1288967\n",
      "epoch: 3 | step: 100 | loss: 0.13189295\n",
      "epoch: 3 | step: 200 | loss: 0.12505148\n",
      "epoch: 3 | step: 300 | loss: 0.124714516\n",
      "epoch: 3 | step: 400 | loss: 0.12684216\n",
      "epoch: 3 | step: 500 | loss: 0.1271186\n",
      "epoch: 3 | step: 600 | loss: 0.124981016\n",
      "epoch: 3 | step: 700 | loss: 0.1281356\n",
      "epoch: 3 | step: 800 | loss: 0.12713104\n",
      "epoch: 3 | step: 900 | loss: 0.12738769\n",
      "epoch: 4 | step: 0 | loss: 0.13017255\n",
      "epoch: 4 | step: 100 | loss: 0.12690565\n",
      "epoch: 4 | step: 200 | loss: 0.12804621\n",
      "epoch: 4 | step: 300 | loss: 0.12721762\n",
      "epoch: 4 | step: 400 | loss: 0.1316621\n",
      "epoch: 4 | step: 500 | loss: 0.12556131\n",
      "epoch: 4 | step: 600 | loss: 0.13211323\n",
      "epoch: 4 | step: 700 | loss: 0.13215329\n",
      "epoch: 4 | step: 800 | loss: 0.12991817\n",
      "epoch: 4 | step: 900 | loss: 0.13124132\n",
      "epoch: 5 | step: 0 | loss: 0.12957287\n",
      "epoch: 5 | step: 100 | loss: 0.12352035\n",
      "epoch: 5 | step: 200 | loss: 0.12815699\n",
      "epoch: 5 | step: 300 | loss: 0.12969284\n",
      "epoch: 5 | step: 400 | loss: 0.12582788\n",
      "epoch: 5 | step: 500 | loss: 0.12897006\n",
      "epoch: 5 | step: 600 | loss: 0.12920918\n",
      "epoch: 5 | step: 700 | loss: 0.13151193\n",
      "epoch: 5 | step: 800 | loss: 0.13109773\n",
      "epoch: 5 | step: 900 | loss: 0.12822522\n",
      "epoch: 6 | step: 0 | loss: 0.1305376\n",
      "epoch: 6 | step: 100 | loss: 0.13051075\n",
      "epoch: 6 | step: 200 | loss: 0.13189264\n",
      "epoch: 6 | step: 300 | loss: 0.12630458\n",
      "epoch: 6 | step: 400 | loss: 0.12590641\n",
      "epoch: 6 | step: 500 | loss: 0.12813264\n",
      "epoch: 6 | step: 600 | loss: 0.1261605\n",
      "epoch: 6 | step: 700 | loss: 0.13127433\n",
      "epoch: 6 | step: 800 | loss: 0.13168636\n",
      "epoch: 6 | step: 900 | loss: 0.13373706\n",
      "epoch: 7 | step: 0 | loss: 0.12843965\n",
      "epoch: 7 | step: 100 | loss: 0.1321415\n",
      "epoch: 7 | step: 200 | loss: 0.13304669\n",
      "epoch: 7 | step: 300 | loss: 0.13455904\n",
      "epoch: 7 | step: 400 | loss: 0.1300021\n",
      "epoch: 7 | step: 500 | loss: 0.13046075\n",
      "epoch: 7 | step: 600 | loss: 0.13030162\n",
      "epoch: 7 | step: 700 | loss: 0.12925477\n",
      "epoch: 7 | step: 800 | loss: 0.1346667\n",
      "epoch: 7 | step: 900 | loss: 0.13260911\n",
      "epoch: 8 | step: 0 | loss: 0.12944119\n",
      "epoch: 8 | step: 100 | loss: 0.13411427\n",
      "epoch: 8 | step: 200 | loss: 0.12971291\n",
      "epoch: 8 | step: 300 | loss: 0.12739016\n",
      "epoch: 8 | step: 400 | loss: 0.1290522\n",
      "epoch: 8 | step: 500 | loss: 0.12643419\n",
      "epoch: 8 | step: 600 | loss: 0.12662038\n",
      "epoch: 8 | step: 700 | loss: 0.1318152\n",
      "epoch: 8 | step: 800 | loss: 0.13614912\n",
      "epoch: 8 | step: 900 | loss: 0.13280568\n",
      "epoch: 9 | step: 0 | loss: 0.13132867\n",
      "epoch: 9 | step: 100 | loss: 0.13007087\n",
      "epoch: 9 | step: 200 | loss: 0.13560292\n",
      "epoch: 9 | step: 300 | loss: 0.12939651\n",
      "epoch: 9 | step: 400 | loss: 0.12948713\n",
      "epoch: 9 | step: 500 | loss: 0.1294827\n",
      "epoch: 9 | step: 600 | loss: 0.13549587\n",
      "epoch: 9 | step: 700 | loss: 0.13615814\n",
      "epoch: 9 | step: 800 | loss: 0.1284575\n",
      "epoch: 9 | step: 900 | loss: 0.13096038\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        b_x = batch_x.view(-1, 28*28)\n",
    "        b_y = batch_x.view(-1, 28*28)\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "        loss = loss_func(decoded, b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"epoch:\", epoch, \"| step:\", step, \"| loss:\", loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_data = train_data.data[1].type(torch.FloatTensor) / 255.\n",
    "_, decoded = autoencoder(view_data.view(-1, 28*28))\n",
    "plt.imshow(decoded.data.numpy().reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
